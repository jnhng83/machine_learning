{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import argparse\n",
    "import base64\n",
    "import os,glob\n",
    "import numpy as np\n",
    "\n",
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def label_image(photo_file):\n",
    "    \"\"\"Run a label request on a single image\"\"\"\n",
    "\n",
    "    # START authentication\n",
    "    credentials = GoogleCredentials.get_application_default()\n",
    "    service = discovery.build('vision', 'v1', credentials=credentials)\n",
    "    # END authentication\n",
    "\n",
    "    # START constructing request\n",
    "    with open(photo_file, 'rb') as image:\n",
    "        image_content = base64.b64encode(image.read())\n",
    "        service_request = service.images().annotate(body={\n",
    "            'requests': [{\n",
    "                'image': {\n",
    "                    'content': image_content.decode('UTF-8')\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': 'LABEL_DETECTION',\n",
    "                    'maxResults': 5\n",
    "                }]\n",
    "            }]\n",
    "        })\n",
    "        # END constructing request\n",
    "\n",
    "        # START parsing response\n",
    "        response = service_request.execute()\n",
    "        for results in response['responses']:\n",
    "            if 'labelAnnotations' in results:\n",
    "                for annotations in results['labelAnnotations']:\n",
    "                    print('Predicted Label %s, score = %s' % (annotations['description'], annotations['score']))\n",
    "\n",
    "                    \n",
    "def detect_face(photo_file):\n",
    "    \"\"\"Run a face detection request on a single image\"\"\"\n",
    "    \"https://cloud.google.com/vision/docs/reference/rest/v1/images/annotate\"\n",
    "\n",
    "    # START authentication\n",
    "    credentials = GoogleCredentials.get_application_default()\n",
    "    service = discovery.build('vision', 'v1', credentials=credentials)\n",
    "    # END authentication\n",
    "\n",
    "    # START constructing request\n",
    "    with open(photo_file, 'rb') as image:\n",
    "        image_content = base64.b64encode(image.read())\n",
    "        service_request = service.images().annotate(body={\n",
    "            'requests': [{\n",
    "                'image': {\n",
    "                    'content': image_content.decode('UTF-8')\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': 'FACE_DETECTION',\n",
    "                    'maxResults': 5\n",
    "                }]\n",
    "            }]\n",
    "        })\n",
    "        # END constructing request\n",
    "\n",
    "        # START parsing response\n",
    "        face_position_list = []\n",
    "        head_position_list = []\n",
    "        response = service_request.execute()\n",
    "        for results in response['responses']:\n",
    "            if 'faceAnnotations' in results:\n",
    "                for face_id, annotations in enumerate(results['faceAnnotations']):\n",
    "                    #print('Predicted Label %s, score = %s' % (annotations['description'], annotations['score']))\n",
    "                    print(\"======================================\")\n",
    "                    print(\"Detected Face %d with confidence %f\" %(face_id+1, annotations['detectionConfidence']))\n",
    "                    print(\"    Joyful : %s\" %(annotations['joyLikelihood']))\n",
    "                    print(\"    Sorrowful : %s\" %(annotations['sorrowLikelihood']))\n",
    "                    print(\"    Surpised : %s\" %(annotations['surpriseLikelihood']))\n",
    "                    print(\"    Angry : %s\" %(annotations['angerLikelihood']))\n",
    "                    face_position_list.append(annotations['fdBoundingPoly']['vertices'])\n",
    "                    head_position_list.append(annotations['boundingPoly']['vertices'])\n",
    "                    \n",
    "            else :\n",
    "                print(\"No Face is Detected !!\")\n",
    "        \n",
    "        \n",
    "    return face_position_list, head_position_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Query Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "facetime_path = '/Users/Vuno/Pictures/Photo Booth 보관함/Pictures'\n",
    "file_name = sorted(glob.glob(facetime_path+'/*.jpg'), key=os.path.getmtime)[-1]\n",
    "\n",
    "img = Image.open(file_name)\n",
    "plt.imshow(np.asanyarray(img))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Object Labeling using JSON request and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "label_image(file_name)\n",
    "#face_positions, head_positions = detect_face(last_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Face Detection using JSON request and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set File Path\n",
    "file_name = './queen.jpeg'\n",
    "img = Image.open(file_name)\n",
    "\n",
    "# Send Request using JSON request\n",
    "face_positions, head_positions = detect_face(file_name)\n",
    "\n",
    "# Draw Face Detection Result\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(np.asanyarray(img))\n",
    "\n",
    "for head_pos in head_positions:\n",
    "    x0 = head_pos[0]['x']\n",
    "    y0 = head_pos[0]['y']\n",
    "    width = head_pos[2]['x'] - x0\n",
    "    height = head_pos[2]['y'] - y0\n",
    "    rect = patches.Rectangle((x0, y0), width, height, linewidth=1, edgecolor='g', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
