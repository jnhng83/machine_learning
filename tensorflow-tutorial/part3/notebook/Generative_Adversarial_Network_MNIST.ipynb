{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Generator and Descriminator Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(128*7*7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Reshape((128, 7, 7), input_shape=(128*7*7,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(1, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model\n",
    "\n",
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same', input_shape=(1, 28, 28)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(128, 5, 5))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Function for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[2:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]), dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[0, :, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mini_batch = 100\n",
    "max_epoch = 100\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train.reshape((X_train.shape[0], 1) + X_train.shape[1:])\n",
    "discriminator = discriminator_model()\n",
    "generator = generator_model()\n",
    "discriminator_on_generator = generator_containing_discriminator(generator, discriminator)\n",
    "d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "discriminator_on_generator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "discriminator.trainable = True\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "noise = np.zeros((mini_batch, 100))\n",
    "\n",
    "K.get_session().run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    print(\"Epoch is\", epoch)\n",
    "    print(\"Number of batches\", int(X_train.shape[0]/mini_batch))\n",
    "    for index in range(int(X_train.shape[0]/mini_batch)):\n",
    "        for i in range(mini_batch):\n",
    "            noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "        image_batch = X_train[index*mini_batch:(index+1)*mini_batch]\n",
    "        generated_images = generator.predict(noise, verbose=0)\n",
    "        if index % 20 == 0:\n",
    "            image = combine_images(generated_images)\n",
    "            image = image*127.5+127.5\n",
    "            Image.fromarray(image.astype(np.uint8)).save('./output/'+str(epoch)+\"_\"+str(index)+\".png\")\n",
    "        X = np.concatenate((image_batch, generated_images))\n",
    "        y = [1] * mini_batch + [0] * mini_batch\n",
    "        d_loss = discriminator.train_on_batch(X, y)\n",
    "        #print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "        for i in range(mini_batch):\n",
    "            noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "        discriminator.trainable = False\n",
    "        g_loss = discriminator_on_generator.train_on_batch(noise, [1] * mini_batch)\n",
    "        discriminator.trainable = True\n",
    "        print(\"Epoch : %d, Iter %d, D_loss : %f, G_loss : %f\" % (epoch, index, d_loss, g_loss))\n",
    "        if index % 10 == 9:\n",
    "            generator.save_weights('./models/generator', True)\n",
    "            discriminator.save_weights('./models/discriminator', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Images using Trained GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nice = True\n",
    "num_generate = 100\n",
    "\n",
    "generator = generator_model()\n",
    "generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "generator.load_weights('./models/generator')\n",
    "if nice:\n",
    "    discriminator = discriminator_model()\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    discriminator.load_weights('./models/discriminator')\n",
    "    noise = np.zeros((num_generate*20, 100))\n",
    "    for i in range(num_generate*20):\n",
    "        noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "    generated_images = generator.predict(noise, verbose=1)\n",
    "    d_pret = discriminator.predict(generated_images, verbose=1)\n",
    "    index = np.arange(0, num_generate*20)\n",
    "    index.resize((num_generate*20, 1))\n",
    "    pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "    pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "    nice_images = np.zeros((num_generate, 1) + (generated_images.shape[2:]), dtype=np.float32)\n",
    "    for i in range(int(num_generate)):\n",
    "        idx = int(pre_with_index[i][1])\n",
    "        nice_images[i, 0, :, :] = generated_images[idx, 0, :, :]\n",
    "    image = combine_images(nice_images)\n",
    "else:\n",
    "    noise = np.zeros((num_generate, 100))\n",
    "    for i in range(num_generate):\n",
    "        noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "    generated_images = generator.predict(noise, verbose=1)\n",
    "    image = combine_images(generated_images)\n",
    "image = image*127.5+127.5\n",
    "image = image.astype(np.uint8)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
