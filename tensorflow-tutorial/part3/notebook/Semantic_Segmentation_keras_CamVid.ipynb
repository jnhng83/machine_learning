{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.core import Activation, Reshape, Permute\n",
    "from keras.layers.convolutional import Convolution2D, Deconvolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.visualize_util import plot\n",
    "\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Paths and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530, 360, 480, 3) (530, 360, 480) (530, 360, 480, 12)\n",
      "(171, 360, 480, 3) (171, 360, 480) (171, 360, 480, 12)\n"
     ]
    }
   ],
   "source": [
    "train_input_path = './data/CamVid/train_input.npy'\n",
    "train_label_path = './data/CamVid/train_label.npy'\n",
    "test_input_path = './data/CamVid/test_input.npy'\n",
    "test_label_path = './data/CamVid/test_label.npy'\n",
    "\n",
    "train_input_mat = np.load(train_input_path)\n",
    "train_label_mat = np.load(train_label_path)\n",
    "test_input_mat = np.load(test_input_path)\n",
    "test_label_mat = np.load(test_label_path)\n",
    "\n",
    "n_train = train_input_mat.shape[0]\n",
    "n_test = test_input_mat.shape[0]\n",
    "img_width = train_input_mat.shape[1]\n",
    "img_height = train_input_mat.shape[2]\n",
    "n_class = 12\n",
    "\n",
    "train_label_mat_bin = np.reshape(to_categorical(np.reshape(train_label_mat, -1)), \n",
    "                                 np.shape(train_label_mat) +(n_class,))\n",
    "test_label_mat_bin = np.reshape(to_categorical(np.reshape(test_label_mat, -1)), \n",
    "                                np.shape(test_label_mat) +(n_class,))\n",
    "\n",
    "print train_input_mat.shape, train_label_mat.shape, train_label_mat_bin.shape\n",
    "print test_input_mat.shape, test_label_mat.shape, test_label_mat_bin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SegNet():\n",
    "\n",
    "    # Encoder Part ===================================================================\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(img_width, img_height, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    # Bottleneck Part ===================================================================\n",
    "    model.add(Convolution2D(256, 3, 3, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Decoder Part\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(n_class, 3, 3, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Reshape for Cross-Entropy Calculation\n",
    "    model.add(Reshape((img_width*img_height, n_class)))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Compile Done!\n"
     ]
    }
   ],
   "source": [
    "seg_model = SegNet()\n",
    "optimizer = SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False)\n",
    "seg_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "print 'Model Compile Done!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Train on 530 samples, validate on 171 samples\n",
      "Epoch 1/20\n",
      "530/530 [==============================] - 77s - loss: 2.1793 - acc: 0.3236 - val_loss: 2.3919 - val_acc: 0.1973\n",
      "Epoch 2/20\n",
      "530/530 [==============================] - 61s - loss: 1.6147 - acc: 0.5647 - val_loss: 2.1971 - val_acc: 0.3229\n",
      "Epoch 3/20\n",
      "530/530 [==============================] - 62s - loss: 1.4242 - acc: 0.6534 - val_loss: 2.0207 - val_acc: 0.4187\n",
      "Epoch 4/20\n",
      "530/530 [==============================] - 63s - loss: 1.3100 - acc: 0.6966 - val_loss: 1.8397 - val_acc: 0.4940\n",
      "Epoch 5/20\n",
      "530/530 [==============================] - 63s - loss: 1.2169 - acc: 0.7229 - val_loss: 1.6827 - val_acc: 0.5181\n",
      "Epoch 6/20\n",
      "530/530 [==============================] - 63s - loss: 1.1403 - acc: 0.7445 - val_loss: 1.5465 - val_acc: 0.5732\n",
      "Epoch 7/20\n",
      "530/530 [==============================] - 63s - loss: 1.0793 - acc: 0.7582 - val_loss: 1.4573 - val_acc: 0.6130\n",
      "Epoch 8/20\n",
      "530/530 [==============================] - 63s - loss: 1.0325 - acc: 0.7678 - val_loss: 1.2432 - val_acc: 0.6834\n",
      "Epoch 9/20\n",
      "530/530 [==============================] - 63s - loss: 0.9822 - acc: 0.7789 - val_loss: 1.3538 - val_acc: 0.6468\n",
      "Epoch 10/20\n",
      "530/530 [==============================] - 63s - loss: 0.9445 - acc: 0.7857 - val_loss: 1.1452 - val_acc: 0.7103\n",
      "Epoch 11/20\n",
      "530/530 [==============================] - 63s - loss: 0.9182 - acc: 0.7877 - val_loss: 1.0637 - val_acc: 0.7386\n",
      "Epoch 12/20\n",
      "530/530 [==============================] - 63s - loss: 0.8806 - acc: 0.7973 - val_loss: 0.9923 - val_acc: 0.7508\n",
      "Epoch 13/20\n",
      "530/530 [==============================] - 63s - loss: 0.8566 - acc: 0.8004 - val_loss: 1.0297 - val_acc: 0.7397\n",
      "Epoch 14/20\n",
      "530/530 [==============================] - 63s - loss: 0.8386 - acc: 0.8017 - val_loss: 2.1089 - val_acc: 0.4548\n",
      "Epoch 15/20\n",
      "530/530 [==============================] - 63s - loss: 0.8223 - acc: 0.8031 - val_loss: 1.1844 - val_acc: 0.6404\n",
      "Epoch 16/20\n",
      "530/530 [==============================] - 63s - loss: 0.7980 - acc: 0.8079 - val_loss: 1.3444 - val_acc: 0.6118\n",
      "Epoch 17/20\n",
      "530/530 [==============================] - 63s - loss: 0.7725 - acc: 0.8142 - val_loss: 0.9873 - val_acc: 0.7429\n",
      "Epoch 18/20\n",
      "530/530 [==============================] - 63s - loss: 0.7565 - acc: 0.8172 - val_loss: 0.9853 - val_acc: 0.7428\n",
      "Epoch 19/20\n",
      "530/530 [==============================] - 63s - loss: 0.7427 - acc: 0.8188 - val_loss: 0.9162 - val_acc: 0.7576\n",
      "Epoch 20/20\n"
     ]
    }
   ],
   "source": [
    "print \"Starting Training...\"\n",
    "\n",
    "train_X = train_input_mat\n",
    "train_Y = np.reshape(train_label_mat_bin, (n_train, img_width*img_height, n_class))\n",
    "test_X = test_input_mat\n",
    "test_Y = np.reshape(test_label_mat_bin, (n_test, img_width*img_height, n_class))\n",
    "\n",
    "checkpoint_path=\"./checkpoint/CamVid_epoch_{epoch:02d}_acc_{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=0, \n",
    "                             save_best_only=True, save_weights_only=False, mode='auto')\n",
    "seg_model.fit(train_X, train_Y, nb_epoch=20, batch_size=16, verbose=1, validation_data=(test_X, test_Y), callbacks=[checkpoint])\n",
    "\n",
    "print \"Training Completed!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segment Test Scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(test_X)\n",
    "predicted = np.reshape(predicted, (n_test, img_width, img_height, n_class))\n",
    "print np.shape(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vis_ind = 100\n",
    "label_img = np.argmax(test_label_mat_bin[vis_ind, :, :, :], axis=2)\n",
    "pred_img = np.argmax(predicted[vis_ind, :, :, :], axis=2)\n",
    "\n",
    "plt.imshow(test_X[vis_ind, :, :, :])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(label_img)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(pred_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
